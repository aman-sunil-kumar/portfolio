# Data Scientist

### Education
Data Analytics Engineering, MS
Mechanical Engineering, B.Tech

### Work Experience
Data Analyst @ Pantone (X-rite Pantone, Veralto)
- Data Engineering:
- Engineered and optimized scalable AWS Glue ETL pipelines, automating the ingestion, transformation, and loading of terabyte-scale datasets from RDBMS and NoSQL sources into a centralized S3 data lake, reducing processing latency by 70% and enabling real-time analytics through partitioning, bucketing, and optimized data serialization formats (Parquet, ORC).
- Architected end-to-end data pipelines for tracking user adoption and feature engagement in Pantone Connect, integrating Google Analytics with user interaction data and session logs, implementing time-series analysis and anomaly detection to improve user experience and increase adoption by 20%.
- Data Science:
- Developed and applied advanced clustering algorithms (k-means, DBSCAN) for unsupervised user segmentation, leveraging principal component analysis (PCA) for dimensionality reduction, leading to a 10% increase in retention through personalized recommendations.
- Utilized natural language processing (NLP) techniques, such as topic modeling and sentiment analysis, to extract insights from customer feedback, identifying pain points and trends that informed product enhancements, contributing to a 15% improvement in user satisfaction.
- Automated executive-level Power BI dashboards using complex DAX expressions and SQL queries, providing real-time insights into KPIs, churn, and conversion rates, leveraging star-schema data modeling for efficient reporting and decision-making.

### Projects
Predictive Credit Scoring Model for Loan Repayment Risk Assessment
- Developed a machine learning-based credit scoring model to predict loan repayment likelihood, leveraging logistic regression for classifying borrowers into "good" and "bad" credit risks, enhancing decision-making across loan approval, pricing, and refinancing processes.
- Performed Exploratory Data Analysis (EDA), including outlier treatment through flooring and capping, and missing value imputation (central tendency and class mean substitution), ensuring data quality and robustness for model building.
- Utilized Weight of Evidence (WOE) transformation for categorical variable substitution, and Information Value (IV) analysis to select strong predictors, improving model interpretability and predictive power.
- Engineered scorecards by scaling logistic regression coefficients, creating a scoring system that intuitively represents the risk levels of borrowers, used by financial institutions for credit decisioning and portfolio risk management.
- Evaluated model performance using confusion matrix metrics (accuracy, precision, recall, F-score), ensuring the final model delivered reliable predictions that aligned with business objectives in loan portfolios.
